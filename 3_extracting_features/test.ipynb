{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import pathlib\n",
    "\n",
    "def copy_DP_files(\n",
    "    project_path: pathlib.Path,\n",
    "    config_name: str,\n",
    "    checkpoint_name: str,\n",
    "):\n",
    "    \"\"\"copy config and checkpoint files to their necessary location in DP project (located at project path)\n",
    "    Args:\n",
    "        project_path (pathlib.Path): path for DP project\n",
    "        config_name (str): name of config file to copy\n",
    "        checkpoint_name (str): name of checkpoint file to copy\n",
    "    \"\"\"\n",
    "\n",
    "    # copy config file to DP project\n",
    "    config_load_path = pathlib.Path(f\"DP_files/{config_name}\")\n",
    "    config_save_path = pathlib.Path(f\"{project_path}/inputs/config/{config_name}\")\n",
    "    config_save_path.parents[0].mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copyfile(config_load_path, config_save_path)\n",
    "\n",
    "    # copy checkpoint file to DP project\n",
    "    checkpoint_load_path = pathlib.Path(f\"DP_files/{checkpoint_name}\")\n",
    "    checkpoint_save_path = pathlib.Path(\n",
    "        f\"{project_path}/outputs/efn_pretrained/checkpoint/{checkpoint_name}\"\n",
    "    )\n",
    "    checkpoint_save_path.parents[0].mkdir(parents=True)\n",
    "    shutil.copyfile(checkpoint_load_path, checkpoint_save_path)\n",
    "\n",
    "    # WORKS!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = pathlib.Path('NF1_nuc_project-DP')\n",
    "config_name = 'NF1_nuc_config.json'\n",
    "checkpoint_name = 'efficientnet-b0_weights_tf_dim_ordering_tf_kernels_autoaugment.h5'\n",
    "\n",
    "copy_DP_files(project_path, config_name, checkpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "def compile_index_csv(\n",
    "    images_load_path: pathlib.Path,\n",
    "    DP_images_path: pathlib.Path,\n",
    "    annotations: pd.DataFrame,\n",
    "    object: str,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Compiles index csv file (image metadata, channel image locations, genotype)\n",
    "    Args:\n",
    "        images_load_path (pathlib.Path): Path to load illuminated corrected images from \n",
    "        DP_images_path (pathlib.Path): Path to DP project images folder (DP_project/inputs/images)\n",
    "        annotations (pd.DataFrame): NF1 data annotations metadata csv file\n",
    "        object (str): Object to compile index csv for, either \"nuc\" (nucleus) or \"cyto\" (cytoplasm)\n",
    "    Returns:\n",
    "        pd.DataFrame: index csv dataframe\n",
    "    \"\"\"\n",
    "    # Empty data frame for index to be appended to\n",
    "    index_csv_data = []\n",
    "\n",
    "    for image_paths in images_load_path.iterdir():\n",
    "        # Skip over files without DAPI in image path name\n",
    "        if \"DAPI\" not in image_paths.name:\n",
    "            continue\n",
    "\n",
    "        # Get image metadata\n",
    "        plate = int(image_paths.name[3:5])\n",
    "        well = image_paths.name[0:2]\n",
    "        site = image_paths.name[8]\n",
    "\n",
    "        # Get genotype value for images, assign plate and well columns from annotations for index\n",
    "        image_annotations = annotations.loc[\n",
    "            (plate == annotations[\"Plate\"]) & (annotations[\"Well\"] == well)\n",
    "        ]\n",
    "        genotype = image_annotations.iloc[0][\"Genotype\"]\n",
    "        \n",
    "        # Compile nuclei index file data\n",
    "        if object == \"nuc\":\n",
    "            file_data = {\n",
    "                \"Metadata_Plate\": plate,\n",
    "                \"Metadata_Well\": well,\n",
    "                \"Metadata_Site\": site,\n",
    "                \"Plate_Map_Name\": f\"{plate}_{well}_{site}\",\n",
    "                \"DNA\": os.path.relpath(image_paths, DP_images_path),\n",
    "                \"Genotype\": genotype,\n",
    "                \"Genotype_Replicate\": 1,\n",
    "            }\n",
    "            \n",
    "        # Compile cytoplasm index file data\n",
    "        channel = str(image_paths.name[6])\n",
    "\n",
    "        if object == \"cyto\":\n",
    "            channels = [\"DNA\", \"ER\", \"Actin\"]\n",
    "            channel_paths = []\n",
    "            \n",
    "            file_data = {\n",
    "                \"Metadata_Plate\": plate,\n",
    "                \"Metadata_Well\": well,\n",
    "                \"Metadata_Site\": site,\n",
    "                \"Plate_Map_Name\": f\"{plate}_{well}_{site}\",\n",
    "            }\n",
    "            \n",
    "            for index, channel in enumerate(channels):\n",
    "                channel_path = pathlib.Path(str(image_paths).replace('_1_', f'_{index+1}_'))\n",
    "                if '01_2_' in str(channel_path):\n",
    "                    channel_path = pathlib.Path(str(channel_path).replace('DAPI', 'GFP'))\n",
    "                if '01_3_' in str(channel_path):\n",
    "                    channel_path = pathlib.Path(str(channel_path).replace('DAPI', 'RFP'))\n",
    "                file_data[channel]= os.path.relpath(channel_path, DP_images_path)\n",
    "            \n",
    "            file_data[\"Genotype\"] = genotype\n",
    "            file_data[\"Genotype_Replicate\"] = 1\n",
    "\n",
    "        index_csv_data.append(file_data)\n",
    "\n",
    "        # index_nuc = pd.DataFrame(index_csv_data)\n",
    "        \n",
    "        # project_path = pathlib.Path('NF1_nuc_project-DP')\n",
    "        # index_save_path = pathlib.Path(f'{project_path}/inputs/metadata/index-nuc.csv')\n",
    "        # index_save_path.parents[0].mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # index_nuc.to_csv(index_save_path, index=False)\n",
    "\n",
    "    return pd.DataFrame(index_csv_data)\n",
    "\n",
    "    # WORKS!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_load_path = pathlib.Path('../1_preprocessing_data/Corrected_Images/')\n",
    "DP_images_path = pathlib.Path('NF1_nuc_project-DP/inputs/images')\n",
    "annotations_path = pathlib.Path('DP_files/NF1_annotations.csv')\n",
    "annotations = pd.read_csv(annotations_path)\n",
    "object = 'nuc'\n",
    "\n",
    "compile_index_csv(images_load_path, DP_images_path, annotations, object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "\n",
    "def compile_training_locations(\n",
    "    index_csv_path: pathlib.Path,\n",
    "    segmentation_data_path: pathlib.Path,\n",
    "    save_path: pathlib.Path,\n",
    "    object: str,\n",
    "):\n",
    "    \"\"\"Compile well-site-nuc.csv file with cell locations, saving to save_path/plate/well\n",
    "    Args:\n",
    "        index_csv_path (pathlib.Path): Path to index.csv file for object (nuc or cyto) DeepProfiler project\n",
    "        segmentation_data_path (pathlib.Path): Path to segmentation folder with .tsv locations files\n",
    "        save_path (pathlib.Path): Path to save location files\n",
    "        object (str): Object to find segmentation locations for, either \"nuc\" or \"cyto\"\n",
    "    \"\"\"\n",
    "    # Reads in csv and iterate through the rows from the plate, well and site columns\n",
    "    index_csv = pd.read_csv(index_csv_path)\n",
    "    for index, row in index_csv.iterrows():\n",
    "        plate = row[\"Metadata_Plate\"]\n",
    "        well = row[\"Metadata_Well\"]\n",
    "        site = row[\"Metadata_Site\"]\n",
    "\n",
    "        # Gets identifier string that matches identifier from segmented images tsvs\n",
    "        identifier_details = row[\"DNA\"].split(\"/\")[-1].split(\"_\")[0:4]\n",
    "        identifier_well = identifier_details[0]\n",
    "        identifier_site = identifier_details[3]\n",
    "        identifier = f\"{identifier_well}_{identifier_site}\"\n",
    "\n",
    "        locations_save_path = pathlib.Path(\n",
    "            f\"{save_path}/{plate}/{well}-{site}-Nuclei.csv\"\n",
    "        )\n",
    "\n",
    "        # Skips a field if the locations have already been found\n",
    "        if locations_save_path.is_file():\n",
    "            print(f\"{plate} + {identifier} already has locations compiled!\")\n",
    "        else:\n",
    "\n",
    "            print(f\"Compiling locations for {plate} + {identifier}\")\n",
    "            frame_segmentations_path = pathlib.Path(\n",
    "                f\"{segmentation_data_path}/{identifier}_{object}-segmented.tsv\"\n",
    "            )\n",
    "\n",
    "            # Handle errors for issues like no locations file or no data within file\n",
    "            try:\n",
    "                frame_segmentations = pd.read_csv(\n",
    "                    frame_segmentations_path, delimiter=\"\\t\"\n",
    "                )\n",
    "            except:\n",
    "                print(f\"No segmentation file for {frame_segmentations_path.name}\")\n",
    "                continue\n",
    "            try:\n",
    "                frame_segmentations = frame_segmentations[\n",
    "                    [\"Cell_ID\", \"Location_Center_X\", \"Location_Center_Y\"]\n",
    "                ]\n",
    "            except KeyError:\n",
    "                print(f\"No segmentation data within {frame_segmentations_path}\")\n",
    "                continue\n",
    "            frame_segmentations = frame_segmentations.rename(\n",
    "                columns={\n",
    "                    \"Location_Center_X\": \"Nuclei_Location_Center_X\",\n",
    "                    \"Location_Center_Y\": \"Nuclei_Location_Center_Y\",\n",
    "                }\n",
    "            )\n",
    "\n",
    "            locations_save_path.parents[0].mkdir(parents=True, exist_ok=True)\n",
    "            frame_segmentations.to_csv(locations_save_path, index=False)\n",
    "\n",
    "\n",
    "# WORKS!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling locations for 1 + D6_3\n",
      "Compiling locations for 1 + F6_2\n",
      "Compiling locations for 1 + E7_3\n",
      "Compiling locations for 1 + C6_2\n",
      "Compiling locations for 1 + C7_1\n",
      "Compiling locations for 1 + C7_4\n",
      "Compiling locations for 1 + E6_3\n",
      "Compiling locations for 1 + C6_1\n",
      "Compiling locations for 1 + E7_4\n",
      "Compiling locations for 1 + E7_1\n",
      "Compiling locations for 1 + C6_4\n",
      "Compiling locations for 1 + F7_1\n",
      "Compiling locations for 1 + D7_1\n",
      "Compiling locations for 1 + E6_1\n",
      "Compiling locations for 1 + F6_4\n",
      "Compiling locations for 1 + F7_4\n",
      "Compiling locations for 1 + C6_3\n",
      "Compiling locations for 1 + F6_3\n",
      "Compiling locations for 1 + D6_2\n",
      "Compiling locations for 1 + C7_2\n",
      "Compiling locations for 1 + F7_2\n",
      "Compiling locations for 1 + E6_4\n",
      "Compiling locations for 1 + D6_4\n",
      "Compiling locations for 1 + D6_1\n",
      "Compiling locations for 1 + E6_2\n",
      "Compiling locations for 1 + F6_1\n",
      "Compiling locations for 1 + F7_3\n",
      "Compiling locations for 1 + C7_3\n",
      "Compiling locations for 1 + D7_2\n",
      "Compiling locations for 1 + D7_4\n",
      "Compiling locations for 1 + D7_3\n",
      "Compiling locations for 1 + E7_2\n"
     ]
    }
   ],
   "source": [
    "index_csv_path = pathlib.Path('NF1_nuc_project-DP/inputs/metadata/index-nuc.csv')\n",
    "segmentation_data_path = pathlib.Path('../2_segmenting_data/Segmented_Images/')\n",
    "save_path = pathlib.Path('NF1_nuc_project-DP/inputs/locations/')\n",
    "object = 'nuc'\n",
    "\n",
    "compile_training_locations(index_csv_path, segmentation_data_path, save_path, object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('3.feature-extraction-NF1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "07287d3d53805712e5f12605dc1ae8f1d238b153ace9542d6736ac23e3b05c95"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
